{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with the HathiTrust Corpus & Machine Learning\n",
    "\n",
    "This notebook is based on the [Classifying HTRC Genre notebook](https://github.com/htrc/ACS-TT/blob/master/tools/notebooks/ClassifyingHtrcGenreWordFrequencies.ipynb) and uses data from the [HathiTrust Research Center](https://sharc.hathitrust.org/genre). A few caveats about the provenance and method of selection of the data:\n",
    "- only English\n",
    "- texts published 1700-1799, but may include reprints of earlier materials\n",
    "- volumes held by large public or university libraries, primarily in the United States.\n",
    "- the creators don't recommend the dataset as a source for literary research before 1750, since texts published pre-1800 is often in Special Collections and digitization is less predictable.\n",
    "- A short version: the model's predictions about genre matched human descriptions 93.6% of the time, which is roughly as often as our six human readers agreed with each other (94.5%). Moreover, the datasets provided here have passed through additional (automatic and manual) filtering that allows us to guarantee better than 97% precision.\n",
    "\n",
    "See the HathiTrust Research Center for more observations on normalization, OCR correction, metadata, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right, let's set up our classifier:\n",
    "\n",
    "The first step is to (re)build our philosophical classifier. It's worth reiterating that the classifier is being trained on a relatively small corpus (so isn't likely as representative as it might be) and that the new HTRC genre corpus is literature-specific (so a different kind of beast from our training corpus). Is it still useful as a classifier? that's part of what we'd like to find out.\n",
    "The classifier created below is essentially the same as before, though we'll use the LinearSVC algorithm because it provides a way of not just classifying (philosophical or non-philosophical) but also of expressing a value for how philosophical or not the text is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\broomgrass\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\classes.py:197: DeprecationWarning: loss='l2' has been deprecated in favor of loss='squared_hinge' as of 0.16. Backward compatibility for the loss='l2' will be removed in 1.0\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# define the training corpus to use \n",
    "trav_data_dir = \"C:/Users/broomgrass/iPython/Dream/data/texts\"\n",
    "trav_corpus = nltk.corpus.reader.plaintext.PlaintextCorpusReader(trav_data_dir+\"/modcorpus\", \".*\\.txt\")\n",
    "filtered_fileids = [fileid for fileid in trav_corpus.fileids()]\n",
    "\n",
    "# create TF-IDF (actually relative frequencies) vectorizer\n",
    "stopword_vectorizer = TfidfVectorizer(use_idf=False, stop_words=nltk.corpus.stopwords.words(\"english\"), max_features=10000)\n",
    "X_train = stopword_vectorizer.fit_transform([trav_corpus.raw(fileid) for fileid in filtered_fileids])\n",
    "trav_categories = [\"Other\" if \"Other\" in fileid else \"Travel\" for fileid in filtered_fileids]\n",
    "\n",
    "# create a classifier\n",
    "trav_clf = LinearSVC(loss='l2', penalty=\"l2\", dual=False, tol=1e-3)\n",
    "trav_clf.fit(X_train, trav_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing the HTRC Genre Corpus\n",
    "The HTRC Genre corpus is organized by genre (if you rsync the directory rather than just download the files from the web the files are organized into subfolders by genre). For each genre there's a metadata file with all the volumes for that genre and then a set of compressed archives (.tar.gz) organized by time slice. Our strategy here will be as follows:\n",
    "- for each genre folder (fiction, drama, poetery)\n",
    "- read the metadata file into a table\n",
    "- for each compressed archive in the genre folder (*.tar.gz)\n",
    "    - for each tab-separated values file in the archive\n",
    "create a pseudo text\n",
    "        - for each word-count pair: add the word the specified number of times to our pseuedo text\n",
    "        - produce a classifier decision (a value how philosophical the text is\n",
    "add the prediction value to the corresponding row in the metadata table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import walk\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "import glob\n",
    "\n",
    "def get_genre_metadata_and_predictions(genre_dir, clf, vectorizer):\n",
    "    metadatas = {}\n",
    "    for (dirpath, dirnames, filenames) in walk(htrc_genre_dir):\n",
    "        for genre in dirnames:\n",
    "            genre_path = join(htrc_genre_dir, genre) \n",
    "            metadata = pd.read_csv(join(genre_path, genre+\"_metadata.csv\"), index_col=0)\n",
    "            metadata['prediction'] = [float(0)] * len(metadata)\n",
    "            for tgz in glob.glob(join(genre_path,\"*.tar.gz\")):\n",
    "                print(\"Analyzing \"+tgz)\n",
    "                tar = tarfile.open(tgz, \"r:gz\")\n",
    "                for tarinfo in tar:\n",
    "                    if tarinfo.isreg() and tarinfo.name.endswith(\"tsv\"):\n",
    "\n",
    "                        # read in the TSV file and expand the text (it would probably be quicker to\n",
    "                        # create a vectorizer that can use the feature counts directly, but oh well\n",
    "                        text = \"\"\n",
    "                        tsv = tar.extractfile(tarinfo)\n",
    "                        for line in tsv.readlines():\n",
    "                            word, count = line.decode(\"utf-8\").strip().split(\"\\t\")\n",
    "                            if any(c for c in word if c.isalpha()):\n",
    "                                text += (word + \" \") * int(count)\n",
    "\n",
    "                        # predict the class\n",
    "                        X_test = vectorizer.transform([text])\n",
    "                        metadata['prediction'][tarinfo.name[0:-4]] = clf.decision_function(X_test)[0]\n",
    "\n",
    "                tar.close()\n",
    "            metadatas[genre] = metadata.sort('prediction', ascending=False)\n",
    "        break\n",
    "    return metadatas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should be ready to use our classifier on the HTRC Genre corpus. This returns a dictionary object with keys for each genre (fiction, drama, poetry) and values that are pandas dataframes with all the existing metadata for each volume, plus the philosophical prediction that we've added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "htrc_genre_dir = \"C:/Users/broomgrass/iPython/HathiTrust/data\"\n",
    "trav_metadatas = get_genre_metadata_and_predictions(htrc_genre_dir, trav_clf, stopword_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a quick peek to see how many volumes are contained in each genre:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 0\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for genre, metadata in trav_metadatas.items():\n",
    "    total += len(metadata.index)\n",
    "    print(genre+\": \"+\"{:,}\".format(len(metadata.index)))\n",
    "print(\"total: \"+\"{:,}\".format(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that is *not* what I wanted at all. After looking at everything, I'm not sure exactly where the problem is. My file structure looks like this: <img src=\"screenshot.png\">\n",
    "\n",
    "I suppose a first step is to ask Stefan what the file structure looked like, though this seems to match what was described?\n",
    "\n",
    "A second step is to go through the code more thoroughly, though I have already pored through it and can't see exactly where it went wrong. I changed all the variables to match my own (ie., trav vs philo in the [original notebook](https://github.com/htrc/ACS-TT/blob/master/tools/notebooks/ClassifyingHtrcGenreWordFrequencies.ipynb)) but maybe I missed something? >>> After spending another chunk of time going over it, I don't think I missed a variable. \n",
    "\n",
    "Is it a problem with how my files are being brought in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'fileids'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c732eb3be050>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhtrc_genre_dir\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'fileids'"
     ]
    }
   ],
   "source": [
    "htrc_genre_dir.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'fileids'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3c9584c0c576>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtestfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"C:/Users/broomgrass/iPython/Dream/data/texts/1600-1700corpus\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtestfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'fileids'"
     ]
    }
   ],
   "source": [
    "testfiles = \"C:/Users/broomgrass/iPython/Dream/data/texts/1600-1700corpus\"\n",
    "testfiles.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
