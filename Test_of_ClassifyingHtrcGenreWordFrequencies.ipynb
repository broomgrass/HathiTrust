{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying the HTRC Genre Word Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a part of work being done for the [Trace of Theory project](https://github.com/htrc/ACS-TT), a collaboration between researchers of [NovelTM](http://novel-tm.ca/) and the HathiTrust Research Center ([HTRC](https://www.hathitrust.org/)). In particular, we are wanting to use both [supervised](https://en.wikipedia.org/wiki/Supervised_learning) and [unsupervised](https://en.wikipedia.org/wiki/Unsupervised_learning) machine learning techniques on HTRC texts to gain a better understanding of the extent and nature of theory in various genres.\n",
    "\n",
    "This notebook builds on the [Classifying Philosophical Texts](ClassifyingPhilosophicalText.ipynb) notebook where we looked at building a classifier for philosophical texts, based on a small training corpus. In this notebook we'll try to use a trained classifier to identify philosophical texts based on [genre-specific wordcounts for 178,381 volumes from the HathiTrust Digital Library](https://sharc.hathitrust.org/genre); the genres are fiction, drama and poetry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Philosophical Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to (re)build our [philosophical classifier](ClassifyingPhilosophicalText.ipynb). It's worth reiterating that the classifier is being trained on a relatively small corpus (so isn't likely as representative as it might be) and that the new HTRC genre corpus is literature-specific (so a different kind of beast from our training corpus). Is it still useful as a classifier? that's part of what we'd like to find out.\n",
    "\n",
    "The classifier created below is essentially the [same](ClassifyingPhilosophicalText.ipynb) as before, though we'll use the [LinearSVC](http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html) algorithm because it provides a way of not just classifying (philosophical or non-philosophical) but also of expressing a value for how philosophical or not the text is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\broomgrass\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\classes.py:197: DeprecationWarning: loss='l2' has been deprecated in favor of loss='squared_hinge' as of 0.16. Backward compatibility for the loss='l2' will be removed in 1.0\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# define the training corpus to use (while filtering out our Philosohpical ouliers)\n",
    "philo_data_dir = \"C:/Users/broomgrass/iPython/HathiTrust/ACS-TT-master/ACS-TT-master/data/philosophy\"\n",
    "philo_corpus = nltk.corpus.reader.plaintext.PlaintextCorpusReader(philo_data_dir+\"/texts\", \".*\\.txt\")\n",
    "filtered_fileids = [fileid for fileid in philo_corpus.fileids() if \"GameOfLogic\" not in fileid and \"ThusSpakeZarathustr\" not in fileid]\n",
    "\n",
    "# create TF-IDF (actually elative frequencies) vectorizer\n",
    "stopword_vectorizer = TfidfVectorizer(use_idf=False, stop_words=nltk.corpus.stopwords.words(\"english\"), max_features=10000)\n",
    "X_train = stopword_vectorizer.fit_transform([philo_corpus.raw(fileid) for fileid in filtered_fileids])\n",
    "philo_categories = [\"Philosophy\" if \"Philosophy\" in fileid else \"Other\" for fileid in filtered_fileids]\n",
    "\n",
    "# create a classiier\n",
    "philo_clf = LinearSVC(loss='l2', penalty=\"l2\", dual=False, tol=1e-3)\n",
    "philo_clf.fit(X_train, philo_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the HTRC Genre Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HTRC Genre corpus is organized by genre (if you rsync the directory rather than just download the files from the web the files are organized into subfolders by genre). For each genre there's a metadata file with all the volumes for that genre and then a set of compressed archives (.tar.gz) organized by time slice. Our strategy here will be as follows:\n",
    "\n",
    "* for each genre folder (fiction, drama, poetery)\n",
    "    * read the metadata file into a table\n",
    "    * for each compressed archive in the genre folder (*.tar.gz)\n",
    "        * for each tab-separated values file in the archive\n",
    "            * create a pseudo text \n",
    "            * for each word-count pair: add the word the specified number of times to our pseuedo text\n",
    "            * produce a classifier decision (a value how philosophical the text is\n",
    "            * add the prediction value to the corresponding row in the metadata table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import walk\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "import glob\n",
    "\n",
    "def get_genre_metadata_and_predictions(genre_dir, clf, vectorizer):\n",
    "    metadatas = {}\n",
    "    for (dirpath, dirnames, filenames) in walk(htrc_genre_dir):\n",
    "        for genre in dirnames:\n",
    "            genre_path = join(htrc_genre_dir, genre) \n",
    "            metadata = pd.read_csv(join(genre_path, genre+\"_metadata.csv\"), index_col=0)\n",
    "            metadata['prediction'] = [float(0)] * len(metadata)\n",
    "            for tgz in glob.glob(join(genre_path,\"*.tar.gz\")):\n",
    "                print(\"Analyzing \"+tgz)\n",
    "                tar = tarfile.open(tgz, \"r:gz\")\n",
    "                for tarinfo in tar:\n",
    "                    if tarinfo.isreg() and tarinfo.name.endswith(\"tsv\"):\n",
    "\n",
    "                        # read in the TSV file and expand the text (it would probably be quicker to\n",
    "                        # create a vectorizer that can use the feature counts directly, but oh well\n",
    "                        text = \"\"\n",
    "                        tsv = tar.extractfile(tarinfo)\n",
    "                        for line in tsv.readlines():\n",
    "                            word, count = line.decode(\"utf-8\").strip().split(\"\\t\")\n",
    "                            if any(c for c in word if c.isalpha()):\n",
    "                                text += (word + \" \") * int(count)\n",
    "\n",
    "                        # predict the class\n",
    "                        X_test = vectorizer.transform([text])\n",
    "                        metadata['prediction'][tarinfo.name[0:-4]] = clf.decision_function(X_test)[0]\n",
    "\n",
    "                tar.close()\n",
    "            metadatas[genre] = metadata.sort('prediction', ascending=False)\n",
    "        break\n",
    "    return metadatas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should be ready to use our classifier on the HTRC Genre corpus. This returns a dictionary object with keys for each genre (fiction, drama, poetry) and values that are pandas dataframes with all the existing metadata for each volume, plus the philosophical prediction that we've added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "htrc_genre_dir = \"C:/Users/broomgrass/iPython/HathiTrust/data\"\n",
    "philo_metadatas = get_genre_metadata_and_predictions(htrc_genre_dir, philo_clf, stopword_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a quick peek to see how many volumes are contained in each genre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 0\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for genre, metadata in philo_metadatas.items():\n",
    "    total += len(metadata.index)\n",
    "    print(genre+\": \"+\"{:,}\".format(len(metadata.index)))\n",
    "print(\"total: \"+\"{:,}\".format(total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing Most Philosophical Texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so let's rub our hands together in anticipation and have a closer look at the predictions. For each genre, let's enumerate the 15 most philosophical texts (i.e. the texts that were assigned the highest values by our philosophical classifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for genre, metadata in philo_metadatas.items():\n",
    "    print(genre)\n",
    "    for name, row in metadata.head(15).iterrows():\n",
    "        print(\"  \"+str(row['prediction']) + \": \" + str(row[\"author\"]) + \" \" + str(row[\"title\"])[:40] + \" (\"+ name+\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the things this exposes immediately is that the HTRC genre feature sets contain duplicate texts (presumably because of sampling from different libraries – these aren't identifical files since they're the product of separated digitization and possibly separate editions). This is an annoyance, though we can probably just skip through duplicates in looking at the top samples from each group.\n",
    "\n",
    "Another noticeable thing is the set of 0.0 scores with drama. That score is likely because no prediction was made for the particular text, for some reason. But more importantly, it means that we don't dig very deep in the drama corpus before reaching texts that have negative scores (or zero), which means that the corpus as a whole appears to be less philosohpical. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting by Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our volumes metadata contains date/year values, we can plot the philosophical predictions by year for each genre, this might give us a sense of some diachronic trends, how things change over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "for genre, metadata in philo_metadatas.items():\n",
    "    metadata.plot(kind='scatter', x='date', y='prediction', label=genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clearest thing from these graphs is that all three genres show more variability over time. This is no doubt in part because there are more texts per year as we move forward in time, but that doesn't fully explain the larger discrepencies in scores – it would see that some texts are getting more philosophical while some texts are getting less philosohpical.\n",
    "\n",
    "We also see here a confirmation of our observation earlier about drama being less philosophical, we can eyeball that most scores are under zero. We can observe a crevasse around 1900 in drama, and an even more pronounced gap in poetery at about the same time. This may be caused by an issue with the [HTRC genre feature sets](https://sharc.hathitrust.org/genre) where poetry_1894-1899.tar.gz and drama_1880-1884.tar.gz are empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Means by Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting all 178,381 points makes for very dense scatterplots. Another way to look at change over time is to consider the annual mean philosophical value for each genre. In other words, we look at the average of all the classifier predictions by year, and then comapre by genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAE4CAYAAACHeo0bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSkW5VAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x260a7134748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "for genre, metadata in philo_metadatas.items():\n",
    "    values = {}\n",
    "    for key, grp in metadata.groupby(['date']):\n",
    "        values[key] = grp['prediction'].mean()\n",
    "    plt.plot(list(values.keys()), list(values.values()), label=genre)\n",
    "plt.legend(philo_metadatas.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first century or so shows more fluctuation erratic than the rest (possibly because there are fewer texts sampled). We see the same weirdness (though even clearer here) with drama and poetry that we noticed in the previous plots. Most genres have a graduate drop in philosophically classified texts, with the possible exception of drama."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though our philosophical classifier was created with a relatively small and heterogeneous corpus, it seems useful in trying to identify philosophical texts in the HTRC Genre corpus, as well as suggesting some possible insights about genre and changes over time. In particular:\n",
    "\n",
    "* the HTRC Genre corpus has a lot of duplicate texts\n",
    "* the HTRC Genre corpus increases the number of volumes per year over time\n",
    "* there's an issue with the HTRC Genre corpus around the end of the 19th century\n",
    "* philosophical variation seems to increase over time\n",
    "* drama is the least philosohpical genre\n",
    "* fiction and poetry seem to get less philosophical over time\n",
    "\n",
    "It might be interesting to run the same experiment with the [LitCrit classifier](ClassifyingLitCrit.ipynb).\n",
    "\n",
    "The HTRC Genre corpus is a wonderful resource because it provides well-organized and readily-accessible word frequency values. The next step might be to try something similar on the full HTRC corpus of 4.8 volumes (though likely a subset of that since our classifier has been trained for English texts only)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "(CC-BY) By Stéfan Sinclair, Geoffrey Rockwell and the [Trace of Theory team](https://github.com/htrc/ACS-TT), last updated November 16, 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
